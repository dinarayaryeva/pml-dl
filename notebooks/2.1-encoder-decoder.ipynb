{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68258d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:54.202925Z",
     "iopub.status.busy": "2023-11-02T22:00:54.202429Z",
     "iopub.status.idle": "2023-11-02T22:00:57.802466Z",
     "shell.execute_reply": "2023-11-02T22:00:57.801345Z"
    },
    "papermill": {
     "duration": 3.61356,
     "end_time": "2023-11-02T22:00:57.805633",
     "exception": false,
     "start_time": "2023-11-02T22:00:54.192073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b96082",
   "metadata": {
    "papermill": {
     "duration": 0.007467,
     "end_time": "2023-11-02T22:00:57.821082",
     "exception": false,
     "start_time": "2023-11-02T22:00:57.813615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2338d82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:57.838206Z",
     "iopub.status.busy": "2023-11-02T22:00:57.837713Z",
     "iopub.status.idle": "2023-11-02T22:00:58.510140Z",
     "shell.execute_reply": "2023-11-02T22:00:58.508870Z"
    },
    "papermill": {
     "duration": 0.683761,
     "end_time": "2023-11-02T22:00:58.512488",
     "exception": false,
     "start_time": "2023-11-02T22:00:57.828727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take your fucking hands off my foot!</td>\n",
       "      <td>take your manoos of my shoes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you think you're a dope boy?</td>\n",
       "      <td>you think you're a diler?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she has a broken nose vaginal tears</td>\n",
       "      <td>he has a broken nose and a torn scabbard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bella the only thing that can hurt me is you.</td>\n",
       "      <td>bella you can only hurt me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let's kill your friend see how you feel!</td>\n",
       "      <td>if she killed your friend how would you feel?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source  \\\n",
       "0           take your fucking hands off my foot!   \n",
       "1                   you think you're a dope boy?   \n",
       "2            she has a broken nose vaginal tears   \n",
       "3  bella the only thing that can hurt me is you.   \n",
       "4       let's kill your friend see how you feel!   \n",
       "\n",
       "                                          target  \n",
       "0                  take your manoos of my shoes!  \n",
       "1                      you think you're a diler?  \n",
       "2      he has a broken nose and a torn scabbard.  \n",
       "3                    bella you can only hurt me.  \n",
       "4  if she killed your friend how would you feel?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir_path = 'data/interim/'\n",
    "\n",
    "train_df = pd.read_csv(dir_path + 'train.csv', index_col=0)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()\n",
    "\n",
    "val_df = pd.read_csv(dir_path + 'validate.csv', index_col=0)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0560b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:58.531019Z",
     "iopub.status.busy": "2023-11-02T22:00:58.530098Z",
     "iopub.status.idle": "2023-11-02T22:00:58.540112Z",
     "shell.execute_reply": "2023-11-02T22:00:58.539032Z"
    },
    "papermill": {
     "duration": 0.021821,
     "end_time": "2023-11-02T22:00:58.542589",
     "exception": false,
     "start_time": "2023-11-02T22:00:58.520768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 13\n",
    "\n",
    "\n",
    "class Style:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2148208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:58.560746Z",
     "iopub.status.busy": "2023-11-02T22:00:58.560367Z",
     "iopub.status.idle": "2023-11-02T22:00:58.567240Z",
     "shell.execute_reply": "2023-11-02T22:00:58.566048Z"
    },
    "papermill": {
     "duration": 0.01868,
     "end_time": "2023-11-02T22:00:58.569618",
     "exception": false,
     "start_time": "2023-11-02T22:00:58.550938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ca6d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:58.587327Z",
     "iopub.status.busy": "2023-11-02T22:00:58.586922Z",
     "iopub.status.idle": "2023-11-02T22:00:58.593534Z",
     "shell.execute_reply": "2023-11-02T22:00:58.592337Z"
    },
    "papermill": {
     "duration": 0.018143,
     "end_time": "2023-11-02T22:00:58.595758",
     "exception": false,
     "start_time": "2023-11-02T22:00:58.577615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65409e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:58.614029Z",
     "iopub.status.busy": "2023-11-02T22:00:58.613620Z",
     "iopub.status.idle": "2023-11-02T22:00:58.621032Z",
     "shell.execute_reply": "2023-11-02T22:00:58.619872Z"
    },
    "papermill": {
     "duration": 0.019405,
     "end_time": "2023-11-02T22:00:58.623357",
     "exception": false,
     "start_time": "2023-11-02T22:00:58.603952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source = 'source'\n",
    "target = 'target'\n",
    "\n",
    "def readStyles(df, reverse=False):\n",
    "    \n",
    "    pairs = [(normalizeString(sample[0]), normalizeString(sample[1]) ) for _, sample in train_df[[source, target]].iterrows()]\n",
    "\n",
    "    # Reverse pairs, make instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_style = Style(target)\n",
    "        output_style = Style(source)\n",
    "    else:\n",
    "        input_style = Style(source)\n",
    "        output_style = Style(target)\n",
    "\n",
    "    return input_style, output_style, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffccacf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:00:58.641263Z",
     "iopub.status.busy": "2023-11-02T22:00:58.640888Z",
     "iopub.status.idle": "2023-11-02T22:01:04.071009Z",
     "shell.execute_reply": "2023-11-02T22:01:04.069619Z"
    },
    "papermill": {
     "duration": 5.442851,
     "end_time": "2023-11-02T22:01:04.074339",
     "exception": false,
     "start_time": "2023-11-02T22:00:58.631488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepareData(df,reverse = False):\n",
    "    input_style, output_style, pairs = readStyles(df, reverse)\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_style.addSentence(pair[0])\n",
    "        output_style.addSentence(pair[1])\n",
    "    return input_style, output_style, pairs\n",
    "\n",
    "input_style, output_style, pairs = prepareData(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0827072",
   "metadata": {
    "papermill": {
     "duration": 0.00783,
     "end_time": "2023-11-02T22:01:04.090554",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.082724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6bbeb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.109514Z",
     "iopub.status.busy": "2023-11-02T22:01:04.109078Z",
     "iopub.status.idle": "2023-11-02T22:01:04.117437Z",
     "shell.execute_reply": "2023-11-02T22:01:04.116221Z"
    },
    "papermill": {
     "duration": 0.020504,
     "end_time": "2023-11-02T22:01:04.119880",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.099376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b58fec",
   "metadata": {
    "papermill": {
     "duration": 0.007877,
     "end_time": "2023-11-02T22:01:04.136250",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.128373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3eecf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.154128Z",
     "iopub.status.busy": "2023-11-02T22:01:04.153737Z",
     "iopub.status.idle": "2023-11-02T22:01:04.173394Z",
     "shell.execute_reply": "2023-11-02T22:01:04.172232Z"
    },
    "papermill": {
     "duration": 0.031582,
     "end_time": "2023-11-02T22:01:04.175895",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.144313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4662e31",
   "metadata": {
    "papermill": {
     "duration": 0.007761,
     "end_time": "2023-11-02T22:01:04.191707",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.183946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbae249e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.209826Z",
     "iopub.status.busy": "2023-11-02T22:01:04.209403Z",
     "iopub.status.idle": "2023-11-02T22:01:04.217111Z",
     "shell.execute_reply": "2023-11-02T22:01:04.215562Z"
    },
    "papermill": {
     "duration": 0.019829,
     "end_time": "2023-11-02T22:01:04.219697",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.199868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d9847e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.237928Z",
     "iopub.status.busy": "2023-11-02T22:01:04.237555Z",
     "iopub.status.idle": "2023-11-02T22:01:04.245593Z",
     "shell.execute_reply": "2023-11-02T22:01:04.244315Z"
    },
    "papermill": {
     "duration": 0.020263,
     "end_time": "2023-11-02T22:01:04.248167",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.227904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b984c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.267237Z",
     "iopub.status.busy": "2023-11-02T22:01:04.266259Z",
     "iopub.status.idle": "2023-11-02T22:01:04.276302Z",
     "shell.execute_reply": "2023-11-02T22:01:04.275423Z"
    },
    "papermill": {
     "duration": 0.022012,
     "end_time": "2023-11-02T22:01:04.278466",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.256454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf83304e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.296523Z",
     "iopub.status.busy": "2023-11-02T22:01:04.296090Z",
     "iopub.status.idle": "2023-11-02T22:01:04.303592Z",
     "shell.execute_reply": "2023-11-02T22:01:04.302336Z"
    },
    "papermill": {
     "duration": 0.01926,
     "end_time": "2023-11-02T22:01:04.305870",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.286610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b18989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.324161Z",
     "iopub.status.busy": "2023-11-02T22:01:04.323693Z",
     "iopub.status.idle": "2023-11-02T22:01:04.332084Z",
     "shell.execute_reply": "2023-11-02T22:01:04.330459Z"
    },
    "papermill": {
     "duration": 0.020818,
     "end_time": "2023-11-02T22:01:04.334806",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.313988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04db9e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.352873Z",
     "iopub.status.busy": "2023-11-02T22:01:04.352449Z",
     "iopub.status.idle": "2023-11-02T22:01:04.360877Z",
     "shell.execute_reply": "2023-11-02T22:01:04.359664Z"
    },
    "papermill": {
     "duration": 0.020199,
     "end_time": "2023-11-02T22:01:04.363323",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.343124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(style, sentence):\n",
    "    return [style.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(style, sentence):\n",
    "    indexes = indexesFromSentence(style, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_style, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_style, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d253ae05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.381823Z",
     "iopub.status.busy": "2023-11-02T22:01:04.381443Z",
     "iopub.status.idle": "2023-11-02T22:01:04.390896Z",
     "shell.execute_reply": "2023-11-02T22:01:04.389774Z"
    },
    "papermill": {
     "duration": 0.021781,
     "end_time": "2023-11-02T22:01:04.393205",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.371424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size):\n",
    "    input_style, output_style, pairs = prepareData(train_df)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_style, inp)\n",
    "        tgt_ids = indexesFromSentence(output_style, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_style, output_style, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d52da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T22:01:04.411364Z",
     "iopub.status.busy": "2023-11-02T22:01:04.410943Z",
     "iopub.status.idle": "2023-11-02T23:36:19.559692Z",
     "shell.execute_reply": "2023-11-02T23:36:19.558073Z"
    },
    "papermill": {
     "duration": 5715.167634,
     "end_time": "2023-11-02T23:36:19.568963",
     "exception": false,
     "start_time": "2023-11-02T22:01:04.401329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 18s (- 83m 45s) (5 10%) 2.4809\n",
      "18m 40s (- 74m 41s) (10 20%) 1.5555\n",
      "28m 5s (- 65m 32s) (15 30%) 1.1234\n",
      "37m 35s (- 56m 22s) (20 40%) 0.8839\n",
      "47m 8s (- 47m 8s) (25 50%) 0.7370\n",
      "56m 48s (- 37m 52s) (30 60%) 0.6388\n",
      "66m 30s (- 28m 30s) (35 70%) 0.5645\n",
      "76m 5s (- 19m 1s) (40 80%) 0.5086\n",
      "85m 38s (- 9m 30s) (45 90%) 0.4627\n",
      "95m 9s (- 0m 0s) (50 100%) 0.4257\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 50, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988b7bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T23:36:19.589028Z",
     "iopub.status.busy": "2023-11-02T23:36:19.588637Z",
     "iopub.status.idle": "2023-11-02T23:36:19.595979Z",
     "shell.execute_reply": "2023-11-02T23:36:19.594592Z"
    },
    "papermill": {
     "duration": 0.020401,
     "end_time": "2023-11-02T23:36:19.598499",
     "exception": false,
     "start_time": "2023-11-02T23:36:19.578098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2238e761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T23:36:19.619047Z",
     "iopub.status.busy": "2023-11-02T23:36:19.618654Z",
     "iopub.status.idle": "2023-11-02T23:36:19.744189Z",
     "shell.execute_reply": "2023-11-02T23:36:19.742571Z"
    },
    "papermill": {
     "duration": 0.138609,
     "end_time": "2023-11-02T23:36:19.746781",
     "exception": false,
     "start_time": "2023-11-02T23:36:19.608172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> aw damn !\n",
      "= aw hell !\n",
      "< aw hell ! the shoe ! <EOS>\n",
      "\n",
      "> get the fuck out of here\n",
      "= get out of here\n",
      "< get out of here now <EOS>\n",
      "\n",
      "> i can t wait to get rid of him\n",
      "= honestly i can t wait to get rid of phillip\n",
      "< honestly i can t wait to get rid of phillip <EOS>\n",
      "\n",
      "> he s crazy but he s talented\n",
      "= twisted but talented\n",
      "< he s mad but he s bones <EOS>\n",
      "\n",
      "> a couple of dumb shows never hurt anybody\n",
      "= a couple of rescuers haven t hurt anyone yet\n",
      "< a couple of rescuers haven t hurt anyone yet yet <EOS>\n",
      "\n",
      "> apart from the blood spatters there are chums\n",
      "= some of the blood is smears not spatter\n",
      "< some of the blood is smears not spatter <EOS>\n",
      "\n",
      "> i m sorry grandma it s not as pathetic as you think\n",
      "= sorry grandma not as touching as you think it is\n",
      "< sorry grandma not as touching as you think <EOS>\n",
      "\n",
      "> let go you monster !\n",
      "= let the monster go\n",
      "< let the monster monster ! <EOS>\n",
      "\n",
      "> i can tie you up if you want\n",
      "= if you want i can tie it for you\n",
      "< you want me if you want it to something <EOS>\n",
      "\n",
      "> maybe you don t have the balls\n",
      "= maybe you don t have that kind of nuts\n",
      "< maybe you don t have the guts <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5730.288746,
   "end_time": "2023-11-02T23:36:20.795692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-02T22:00:50.506946",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
